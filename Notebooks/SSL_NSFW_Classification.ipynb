{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51ewsFUA_OcR"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NByNZj20EOup"
   },
   "outputs": [],
   "source": [
    "cd /content/gdrive/'My Drive'/'directory-with-ssl-resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJQaW1v5ES17"
   },
   "outputs": [],
   "source": [
    "#dataset preparation \n",
    "\n",
    "!unzip /content/gdrive/'My Drive'/NSFW_Classification/data.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4-Nu16PEth9"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from resnet_wider import resnet50x1, resnet50x2, resnet50x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9xeQH7ZUE0rz",
    "outputId": "1df9bc96-3197-4dde-cba1-15572fd2f492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = resnet50x1()\n",
    "sd = 'resnet50-1x.pth'\n",
    "'''\n",
    "elif args.arch == 'resnet50-2x':\n",
    "    model = resnet50x2()\n",
    "    sd = 'resnet50-2x.pth'\n",
    "elif args.arch == 'resnet50-4x':\n",
    "    model = resnet50x4()\n",
    "    sd = 'resnet50-4x.pth'\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "'''\n",
    "sd = torch.load(sd, map_location='cpu')\n",
    "model.load_state_dict(sd['state_dict'])\n",
    "\n",
    "model.fc = nn.Identity()\n",
    "model = (model).to('cuda')\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "print(\"Model successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbS1PT7KE2Sz"
   },
   "outputs": [],
   "source": [
    "class TransformsSimCLR:\n",
    "\n",
    "    def __init__(self, size):\n",
    "\n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(size=size),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ezxCcIDE5m0"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.mkdir('models')\n",
    "os.mkdir('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSH9ku1TII6e"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "image_transforms = {\n",
    "    'train':transforms.Compose([\n",
    "        transforms.Resize(size=size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HwKJSuZQHzTF",
    "outputId": "321c6ef2-f497-4cde-d3ca-9cae48490217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14975 2920 2492\n"
     ]
    }
   ],
   "source": [
    "# Set the train, test and validation directory\n",
    "train_directory = '/content/data/train'\n",
    "test_directory = '/content/data/test'\n",
    "valid_directory = '/content/data/valid'\n",
    "\n",
    "# Setting batch size for training\n",
    "batch_size=128\n",
    "\n",
    "#Number of classes for the data\n",
    "num_classes = 5\n",
    "\n",
    "#Loading the data from the folders into the variable 'data'\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['train']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['train'])\n",
    "}\n",
    "\n",
    "#Find out the size of the data\n",
    "train_data_size = len(data['train'])\n",
    "test_data_size = len(data['test'])\n",
    "val_data_size = len(data['valid'])\n",
    "\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_loader = DataLoader(data['train'],batch_size=batch_size,shuffle=True)\n",
    "test_loader = DataLoader(data['test'],batch_size=batch_size,shuffle=True)\n",
    "val_loader = DataLoader(data['valid'],batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#Printing the sizes of the sets\n",
    "print(train_data_size,test_data_size,val_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "TwawRth0IZlc",
    "outputId": "00fa1222-02cb-486d-bba8-1e3c280086db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 2048])\n"
     ]
    }
   ],
   "source": [
    "# For one image and text\n",
    "\n",
    "for step, (x,y) in enumerate(train_loader):\n",
    "  print(x.shape)\n",
    "  x = x.to('cuda')\n",
    "  x = model(x)\n",
    "  print(x.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "BN-tf-xFJfZl",
    "outputId": "f683e516-8794-4f9a-9c4c-10cbc9eb2b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/117]\t Computing features...\n",
      "Step [20/117]\t Computing features...\n",
      "Step [40/117]\t Computing features...\n",
      "Step [60/117]\t Computing features...\n",
      "Step [80/117]\t Computing features...\n",
      "Step [100/117]\t Computing features...\n",
      "Features shape (14975, 2048)\n",
      "Computed train features\n",
      "Step [0/23]\t Computing features...\n",
      "Step [20/23]\t Computing features...\n",
      "Features shape (2920, 2048)\n",
      "Computed test features\n",
      "Step [0/20]\t Computing features...\n",
      "Features shape (2492, 2048)\n"
     ]
    }
   ],
   "source": [
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h = simclr_model(x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, val_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    print(\"Computed train features\")\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    print(\"Computed test features\")\n",
    "    val_x, val_y = inference(val_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y, val_x, val_y\n",
    "\n",
    "train_x, train_y, test_x, test_y, val_x, val_y = get_features(model,train_loader,test_loader,val_loader,'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Uuko1v3sKGom",
    "outputId": "3901cd59-8dcc-4054-b543-98f25c7c66f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainloader successfully made\n",
      "Valloader successfully made\n",
      "Testloader successfully made\n"
     ]
    }
   ],
   "source": [
    "#create dataloader from those features\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, X_val, y_val, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    print(\"Trainloader successfully made\")\n",
    "\n",
    "    val = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    print(\"Valloader successfully made\")\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    print(\"Testloader successfully made\")\n",
    "    return train_loader, test_loader,val_loader\n",
    "\n",
    "train_loader, test_loader, val_loader = create_data_loaders_from_arrays(train_x, train_y, test_x, test_y, val_x, val_y, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTLWtD-HKdhs"
   },
   "outputs": [],
   "source": [
    "class LinearEvaluation(nn.Module):\n",
    "\n",
    "  def __init__(self,num_classes):\n",
    "    super(LinearEvaluation,self).__init__()\n",
    "    self.Linear = nn.Sequential(\n",
    "                                nn.Linear(2048,num_classes,bias=False),\n",
    "                                nn.Softmax(dim=1)\n",
    "                                )\n",
    "  def forward(self,x):\n",
    "    x = self.Linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "fJ0TGw5OKizH",
    "outputId": "00a1c4ad-95ac-4812-a418-b7d4c5db8d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEvaluation(\n",
      "  (Linear): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=5, bias=False)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linmodel = LinearEvaluation(5).to('cuda')\n",
    "print(linmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "8jMzj_miKkPF",
    "outputId": "bd2fb559-5858-4e74-e9e3-a6ca141052ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2048])\n",
      "tensor([0, 1, 1, 4, 1, 1, 0, 4, 4, 4, 2, 0, 3, 4, 2, 3, 2, 3, 3, 0, 1, 1, 3, 4,\n",
      "        1, 2, 3, 1, 3, 3, 0, 1, 1, 0, 1, 3, 2, 4, 2, 2, 2, 1, 3, 0, 4, 0, 2, 1,\n",
      "        2, 2, 3, 0, 0, 2, 3, 2, 2, 4, 3, 3, 4, 1, 3, 1, 1, 3, 3, 3, 1, 4, 2, 1,\n",
      "        2, 3, 1, 3, 1, 1, 0, 1, 3, 1, 1, 3, 1, 2, 3, 1, 0, 3, 1, 1, 3, 1, 3, 2,\n",
      "        2, 4, 3, 4, 1, 4, 3, 2, 2, 4, 1, 1, 4, 1, 2, 2, 1, 4, 4, 2, 1, 3, 4, 2,\n",
      "        4, 3, 3, 2, 4, 2, 0, 2])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "# For one image and label\n",
    "\n",
    "for step, (x,y) in enumerate(train_loader):\n",
    "  print(x.shape)\n",
    "  print(y)\n",
    "  x = x.to('cuda')\n",
    "  x = linmodel(x)\n",
    "  print(x.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YH6v1CgoKnB2"
   },
   "outputs": [],
   "source": [
    "#define train\n",
    "\n",
    "def train(device, loader, model, criterion, optimizer,val_loader):\n",
    "    train_loss_epoch = 0\n",
    "    train_accuracy_epoch = 0\n",
    "    val_loss_epoch = 0\n",
    "    val_accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        train_accuracy_epoch += acc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "    with torch.no_grad():\n",
    "            model.eval()\n",
    "            for step, (x, y) in enumerate(val_loader):\n",
    "                model.zero_grad()\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "\n",
    "                predicted = output.argmax(1)\n",
    "                acc = (predicted == y).sum().item() / y.size(0)\n",
    "                val_accuracy_epoch += acc\n",
    "\n",
    "                val_loss_epoch += loss.item()\n",
    "\n",
    "\n",
    "    return train_loss_epoch, train_accuracy_epoch, val_loss_epoch, val_accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRhd81HFK9Ae"
   },
   "outputs": [],
   "source": [
    "#define test\n",
    "\n",
    "def test(device, loader, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxfHVcH1P4hG"
   },
   "outputs": [],
   "source": [
    "class LinearEvaluation(nn.Module):\n",
    "\n",
    "  def __init__(self,num_classes):\n",
    "    super(LinearEvaluation,self).__init__()\n",
    "    self.Linear = nn.Sequential(\n",
    "                                nn.Linear(2048,num_classes,bias=False),\n",
    "\n",
    "                                )\n",
    "  def forward(self,x):\n",
    "    x = self.Linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "p_c4x7BvK_YE",
    "outputId": "3a7671c9-756f-4ac7-cb8e-e74bcba354a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearEvaluation(\n",
      "  (Linear): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=5, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "linmodel = LinearEvaluation(5).to('cuda')\n",
    "print(linmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "xe2tXpDkLAls",
    "outputId": "fa930280-6049-4462-fe3c-c3898c377b20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t Train Loss: 1.4538166380336142\t Train Accuracy: 0.5329661316373915\t Val Loss: 1.279346239566803\t Accuracy: 0.7071614583333333\n",
      "Epoch [10/100]\t Train Loss: 0.6026655285276918\t Train Accuracy: 0.8140179142270678\t Val Loss: 0.5921848386526107\t Accuracy: 0.8115364583333333\n",
      "Epoch [20/100]\t Train Loss: 0.4857145420506469\t Train Accuracy: 0.8385926669022141\t Val Loss: 0.5049377381801605\t Accuracy: 0.8264322916666667\n",
      "Epoch [30/100]\t Train Loss: 0.43249791886052513\t Train Accuracy: 0.8536861077461472\t Val Loss: 0.4687956377863884\t Accuracy: 0.8365885416666666\n",
      "Epoch [40/100]\t Train Loss: 0.39934752970679194\t Train Accuracy: 0.8627005308230702\t Val Loss: 0.4483228579163551\t Accuracy: 0.8441145833333333\n",
      "Epoch [50/100]\t Train Loss: 0.3755764971431504\t Train Accuracy: 0.8705803301029679\t Val Loss: 0.43502008467912673\t Accuracy: 0.848359375\n",
      "Epoch [60/100]\t Train Loss: 0.3571187935323797\t Train Accuracy: 0.87625660374184\t Val Loss: 0.42568217068910597\t Accuracy: 0.849921875\n",
      "Epoch [70/100]\t Train Loss: 0.3420365859045942\t Train Accuracy: 0.8807982535836866\t Val Loss: 0.41879693120718003\t Accuracy: 0.8503125\n",
      "Epoch [80/100]\t Train Loss: 0.32927472978575617\t Train Accuracy: 0.887009241032371\t Val Loss: 0.4135535329580307\t Accuracy: 0.85421875\n",
      "Epoch [90/100]\t Train Loss: 0.31820381158946925\t Train Accuracy: 0.8902811427417727\t Val Loss: 0.4094769448041916\t Accuracy: 0.8550000000000001\n",
      "Training successfully completed\n",
      "[FINAL]\t Loss: 0.5138815291549849\t Accuracy: 0.8216450668896321\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(linmodel.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 100\n",
    "device = 'cuda'\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_epoch, train_accuracy_epoch, val_loss_epoch, val_accuracy_epoch = train(device, train_loader, linmodel, criterion, optimizer,val_loader)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch [{epoch}/{epochs}]\\t Train Loss: {train_loss_epoch / len(train_loader)}\\t Train Accuracy: {train_accuracy_epoch / len(train_loader)}\\t Val Loss: {val_loss_epoch / len(val_loader)}\\t Accuracy: {val_accuracy_epoch / len(val_loader)}\")\n",
    "\n",
    "print(\"Training successfully completed\")\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(\n",
    "    device, test_loader,linmodel, criterion, optimizer\n",
    ")\n",
    "print(\n",
    "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJeuS2zmLB9c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "SSL_NSFW_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

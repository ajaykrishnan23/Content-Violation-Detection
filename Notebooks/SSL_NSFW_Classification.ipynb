{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSL_NSFW_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ewsFUA_OcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NByNZj20EOup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/'My Drive'/'directory-with-ssl-resnet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJQaW1v5ES17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset preparation \n",
        "\n",
        "!unzip /content/gdrive/'My Drive'/NSFW_Classification/data.zip -d /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4-Nu16PEth9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from resnet_wider import resnet50x1, resnet50x2, resnet50x4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xeQH7ZUE0rz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1df9bc96-3197-4dde-cba1-15572fd2f492"
      },
      "source": [
        "# create model\n",
        "\n",
        "model = resnet50x1()\n",
        "sd = 'resnet50-1x.pth'\n",
        "'''\n",
        "elif args.arch == 'resnet50-2x':\n",
        "    model = resnet50x2()\n",
        "    sd = 'resnet50-2x.pth'\n",
        "elif args.arch == 'resnet50-4x':\n",
        "    model = resnet50x4()\n",
        "    sd = 'resnet50-4x.pth'\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "'''\n",
        "sd = torch.load(sd, map_location='cpu')\n",
        "model.load_state_dict(sd['state_dict'])\n",
        "\n",
        "model.fc = nn.Identity()\n",
        "model = (model).to('cuda')\n",
        "\n",
        "# define loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "print(\"Model successfully loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model successfully loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbS1PT7KE2Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformsSimCLR:\n",
        "\n",
        "    def __init__(self, size):\n",
        "\n",
        "        self.test_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize(size=size),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.train_transform(x), self.train_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ezxCcIDE5m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.mkdir('models')\n",
        "os.mkdir('history')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSH9ku1TII6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = 224\n",
        "image_transforms = {\n",
        "    'train':transforms.Compose([\n",
        "        transforms.Resize(size=size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKJSuZQHzTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "321c6ef2-f497-4cde-d3ca-9cae48490217"
      },
      "source": [
        "# Set the train, test and validation directory\n",
        "train_directory = '/content/data/train'\n",
        "test_directory = '/content/data/test'\n",
        "valid_directory = '/content/data/valid'\n",
        "\n",
        "# Setting batch size for training\n",
        "batch_size=128\n",
        "\n",
        "#Number of classes for the data\n",
        "num_classes = 5\n",
        "\n",
        "#Loading the data from the folders into the variable 'data'\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "    'valid': datasets.ImageFolder(root=valid_directory, transform=image_transforms['train']),\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['train'])\n",
        "}\n",
        "\n",
        "#Find out the size of the data\n",
        "train_data_size = len(data['train'])\n",
        "test_data_size = len(data['test'])\n",
        "val_data_size = len(data['valid'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_loader = DataLoader(data['train'],batch_size=batch_size,shuffle=True)\n",
        "test_loader = DataLoader(data['test'],batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(data['valid'],batch_size=batch_size,shuffle=True)\n",
        "\n",
        "#Printing the sizes of the sets\n",
        "print(train_data_size,test_data_size,val_data_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14975 2920 2492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwawRth0IZlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "00fa1222-02cb-486d-bba8-1e3c280086db"
      },
      "source": [
        "# For one image and text\n",
        "\n",
        "for step, (x,y) in enumerate(train_loader):\n",
        "  print(x.shape)\n",
        "  x = x.to('cuda')\n",
        "  x = model(x)\n",
        "  print(x.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 3, 224, 224])\n",
            "torch.Size([128, 2048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN-tf-xFJfZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "f683e516-8794-4f9a-9c4c-10cbc9eb2b3e"
      },
      "source": [
        "def inference(loader, simclr_model, device):\n",
        "    feature_vector = []\n",
        "    labels_vector = []\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        x = x.to(device)\n",
        "\n",
        "        # get encoding\n",
        "        with torch.no_grad():\n",
        "            h = simclr_model(x)\n",
        "\n",
        "        h = h.detach()\n",
        "\n",
        "        feature_vector.extend(h.cpu().detach().numpy())\n",
        "        labels_vector.extend(y.numpy())\n",
        "\n",
        "        if step % 20 == 0:\n",
        "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
        "\n",
        "    feature_vector = np.array(feature_vector)\n",
        "    labels_vector = np.array(labels_vector)\n",
        "    print(\"Features shape {}\".format(feature_vector.shape))\n",
        "    return feature_vector, labels_vector\n",
        "\n",
        "\n",
        "def get_features(context_model, train_loader, test_loader, val_loader, device):\n",
        "    train_X, train_y = inference(train_loader, context_model, device)\n",
        "    print(\"Computed train features\")\n",
        "    test_X, test_y = inference(test_loader, context_model, device)\n",
        "    print(\"Computed test features\")\n",
        "    val_x, val_y = inference(val_loader, context_model, device)\n",
        "    return train_X, train_y, test_X, test_y, val_x, val_y\n",
        "\n",
        "train_x, train_y, test_x, test_y, val_x, val_y = get_features(model,train_loader,test_loader,val_loader,'cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step [0/117]\t Computing features...\n",
            "Step [20/117]\t Computing features...\n",
            "Step [40/117]\t Computing features...\n",
            "Step [60/117]\t Computing features...\n",
            "Step [80/117]\t Computing features...\n",
            "Step [100/117]\t Computing features...\n",
            "Features shape (14975, 2048)\n",
            "Computed train features\n",
            "Step [0/23]\t Computing features...\n",
            "Step [20/23]\t Computing features...\n",
            "Features shape (2920, 2048)\n",
            "Computed test features\n",
            "Step [0/20]\t Computing features...\n",
            "Features shape (2492, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuko1v3sKGom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3901cd59-8dcc-4054-b543-98f25c7c66f6"
      },
      "source": [
        "#create dataloader from those features\n",
        "\n",
        "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, X_val, y_val, batch_size):\n",
        "    train = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    print(\"Trainloader successfully made\")\n",
        "\n",
        "    val = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    print(\"Valloader successfully made\")\n",
        "\n",
        "    test = torch.utils.data.TensorDataset(\n",
        "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "    print(\"Testloader successfully made\")\n",
        "    return train_loader, test_loader,val_loader\n",
        "\n",
        "train_loader, test_loader, val_loader = create_data_loaders_from_arrays(train_x, train_y, test_x, test_y, val_x, val_y, 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainloader successfully made\n",
            "Valloader successfully made\n",
            "Testloader successfully made\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTLWtD-HKdhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearEvaluation(nn.Module):\n",
        "\n",
        "  def __init__(self,num_classes):\n",
        "    super(LinearEvaluation,self).__init__()\n",
        "    self.Linear = nn.Sequential(\n",
        "                                nn.Linear(2048,num_classes,bias=False),\n",
        "                                nn.Softmax(dim=1)\n",
        "                                )\n",
        "  def forward(self,x):\n",
        "    x = self.Linear(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ0TGw5OKizH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "00a1c4ad-95ac-4812-a418-b7d4c5db8d23"
      },
      "source": [
        "linmodel = LinearEvaluation(5).to('cuda')\n",
        "print(linmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearEvaluation(\n",
            "  (Linear): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=5, bias=False)\n",
            "    (1): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jMzj_miKkPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "bd2fb559-5858-4e74-e9e3-a6ca141052ca"
      },
      "source": [
        "# For one image and label\n",
        "\n",
        "for step, (x,y) in enumerate(train_loader):\n",
        "  print(x.shape)\n",
        "  print(y)\n",
        "  x = x.to('cuda')\n",
        "  x = linmodel(x)\n",
        "  print(x.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 2048])\n",
            "tensor([0, 1, 1, 4, 1, 1, 0, 4, 4, 4, 2, 0, 3, 4, 2, 3, 2, 3, 3, 0, 1, 1, 3, 4,\n",
            "        1, 2, 3, 1, 3, 3, 0, 1, 1, 0, 1, 3, 2, 4, 2, 2, 2, 1, 3, 0, 4, 0, 2, 1,\n",
            "        2, 2, 3, 0, 0, 2, 3, 2, 2, 4, 3, 3, 4, 1, 3, 1, 1, 3, 3, 3, 1, 4, 2, 1,\n",
            "        2, 3, 1, 3, 1, 1, 0, 1, 3, 1, 1, 3, 1, 2, 3, 1, 0, 3, 1, 1, 3, 1, 3, 2,\n",
            "        2, 4, 3, 4, 1, 4, 3, 2, 2, 4, 1, 1, 4, 1, 2, 2, 1, 4, 4, 2, 1, 3, 4, 2,\n",
            "        4, 3, 3, 2, 4, 2, 0, 2])\n",
            "torch.Size([128, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6v1CgoKnB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define train\n",
        "\n",
        "def train(device, loader, model, criterion, optimizer,val_loader):\n",
        "    train_loss_epoch = 0\n",
        "    train_accuracy_epoch = 0\n",
        "    val_loss_epoch = 0\n",
        "    val_accuracy_epoch = 0\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        predicted = output.argmax(1)\n",
        "        acc = (predicted == y).sum().item() / y.size(0)\n",
        "        train_accuracy_epoch += acc\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_epoch += loss.item()\n",
        "        # if step % 100 == 0:\n",
        "        #     print(\n",
        "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
        "        #     )\n",
        "    with torch.no_grad():\n",
        "            model.eval()\n",
        "            for step, (x, y) in enumerate(val_loader):\n",
        "                model.zero_grad()\n",
        "\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                output = model(x)\n",
        "                loss = criterion(output, y)\n",
        "\n",
        "                predicted = output.argmax(1)\n",
        "                acc = (predicted == y).sum().item() / y.size(0)\n",
        "                val_accuracy_epoch += acc\n",
        "\n",
        "                val_loss_epoch += loss.item()\n",
        "\n",
        "\n",
        "    return train_loss_epoch, train_accuracy_epoch, val_loss_epoch, val_accuracy_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRhd81HFK9Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define test\n",
        "\n",
        "def test(device, loader, model, criterion, optimizer):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    model.eval()\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        model.zero_grad()\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        predicted = output.argmax(1)\n",
        "        acc = (predicted == y).sum().item() / y.size(0)\n",
        "        accuracy_epoch += acc\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "\n",
        "    return loss_epoch, accuracy_epoch\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxfHVcH1P4hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearEvaluation(nn.Module):\n",
        "\n",
        "  def __init__(self,num_classes):\n",
        "    super(LinearEvaluation,self).__init__()\n",
        "    self.Linear = nn.Sequential(\n",
        "                                nn.Linear(2048,num_classes,bias=False),\n",
        "\n",
        "                                )\n",
        "  def forward(self,x):\n",
        "    x = self.Linear(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_c4x7BvK_YE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3a7671c9-756f-4ac7-cb8e-e74bcba354a5"
      },
      "source": [
        "linmodel = LinearEvaluation(5).to('cuda')\n",
        "print(linmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearEvaluation(\n",
            "  (Linear): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=5, bias=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2tXpDkLAls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "fa930280-6049-4462-fe3c-c3898c377b20"
      },
      "source": [
        "optimizer = torch.optim.Adam(linmodel.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "epochs = 100\n",
        "device = 'cuda'\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss_epoch, train_accuracy_epoch, val_loss_epoch, val_accuracy_epoch = train(device, train_loader, linmodel, criterion, optimizer,val_loader)\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch [{epoch}/{epochs}]\\t Train Loss: {train_loss_epoch / len(train_loader)}\\t Train Accuracy: {train_accuracy_epoch / len(train_loader)}\\t Val Loss: {val_loss_epoch / len(val_loader)}\\t Accuracy: {val_accuracy_epoch / len(val_loader)}\")\n",
        "\n",
        "print(\"Training successfully completed\")\n",
        "\n",
        "# final testing\n",
        "loss_epoch, accuracy_epoch = test(\n",
        "    device, test_loader,linmodel, criterion, optimizer\n",
        ")\n",
        "print(\n",
        "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/100]\t Train Loss: 1.4538166380336142\t Train Accuracy: 0.5329661316373915\t Val Loss: 1.279346239566803\t Accuracy: 0.7071614583333333\n",
            "Epoch [10/100]\t Train Loss: 0.6026655285276918\t Train Accuracy: 0.8140179142270678\t Val Loss: 0.5921848386526107\t Accuracy: 0.8115364583333333\n",
            "Epoch [20/100]\t Train Loss: 0.4857145420506469\t Train Accuracy: 0.8385926669022141\t Val Loss: 0.5049377381801605\t Accuracy: 0.8264322916666667\n",
            "Epoch [30/100]\t Train Loss: 0.43249791886052513\t Train Accuracy: 0.8536861077461472\t Val Loss: 0.4687956377863884\t Accuracy: 0.8365885416666666\n",
            "Epoch [40/100]\t Train Loss: 0.39934752970679194\t Train Accuracy: 0.8627005308230702\t Val Loss: 0.4483228579163551\t Accuracy: 0.8441145833333333\n",
            "Epoch [50/100]\t Train Loss: 0.3755764971431504\t Train Accuracy: 0.8705803301029679\t Val Loss: 0.43502008467912673\t Accuracy: 0.848359375\n",
            "Epoch [60/100]\t Train Loss: 0.3571187935323797\t Train Accuracy: 0.87625660374184\t Val Loss: 0.42568217068910597\t Accuracy: 0.849921875\n",
            "Epoch [70/100]\t Train Loss: 0.3420365859045942\t Train Accuracy: 0.8807982535836866\t Val Loss: 0.41879693120718003\t Accuracy: 0.8503125\n",
            "Epoch [80/100]\t Train Loss: 0.32927472978575617\t Train Accuracy: 0.887009241032371\t Val Loss: 0.4135535329580307\t Accuracy: 0.85421875\n",
            "Epoch [90/100]\t Train Loss: 0.31820381158946925\t Train Accuracy: 0.8902811427417727\t Val Loss: 0.4094769448041916\t Accuracy: 0.8550000000000001\n",
            "Training successfully completed\n",
            "[FINAL]\t Loss: 0.5138815291549849\t Accuracy: 0.8216450668896321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJeuS2zmLB9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
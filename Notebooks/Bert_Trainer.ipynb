{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Bert_Trainer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU_71FdVQRc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "65bb9228-8c11-49da-b194-74899a159c54"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.2MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 40.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=c3b0afa25727b42f95fd625d74e288672722095f772ec92dc6bfe6491556795e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eCPx2M0Ro4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1838f798-2203-4ec4-eae1-353841dde042"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bimIVsvaQHsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import logging\n",
        "import time\n",
        "from platform import python_version\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfHD4gikRxA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6a3a040-0199-4473-a3a9-9dfa8f97ce11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj8cC7IlR2Sn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c411f2d-e01b-4512-d26b-7481a9de1328"
      },
      "source": [
        "cd /content/drive/My Drive/kaggle_toxic_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kaggle_toxic_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMswDlNuR4Rt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "92d5114a-c3bd-4889-fe7e-620dce839b85"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv.zip  test.csv.zip         train.csv      Untitled.ipynb\n",
            "test.csv                   test_labels.csv.zip  train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zra-CGZnQHsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh-RA_lpQHsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "df = df.sample(frac=1)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IArlrN7IQHsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f63e8ba3-8761-4b7a-b180-d12e6449eea8"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7ca72b5b9c688e9e</td>\n",
              "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c03f72fd8f8bf54f</td>\n",
              "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9e5b8e8fc1ff2e84</td>\n",
              "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5332799e706665a6</td>\n",
              "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dfa7d8f0b4366680</td>\n",
              "      <td>(and if such phrase exists, it would be provid...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  7ca72b5b9c688e9e  ...             0\n",
              "1  c03f72fd8f8bf54f  ...             0\n",
              "2  9e5b8e8fc1ff2e84  ...             0\n",
              "3  5332799e706665a6  ...             0\n",
              "4  dfa7d8f0b4366680  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxnD7nG-QHst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "713b0e29-89fe-4ddb-afb9-48d4eaefb099"
      },
      "source": [
        "df.comment_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"Geez, are you forgetful!  We've already discussed why Marx  was  not an anarchist, i.e. he wanted to use a State to mold his 'socialist man.'  Ergo, he is a statist - the opposite of an  anarchist.  I know a guy who says that, when he gets old and his teeth fall out, he'll quit eating meat.  Would you call him a vegetarian?\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqaWYv0sQHsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "36cbc8df-6142-4468-e96b-1fb3ffff91f7"
      },
      "source": [
        "target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "df.iloc[[103]][target_columns]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
              "103      1             1        1       0       1              0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnqIFHIoQHs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[:6000].reset_index(drop=True)\n",
        "df_val = df[10000:11000].reset_index(drop=True)\n",
        "df_test = df[11000:13000].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kjB7yZTQHs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class = transformers.BertModel\n",
        "tokenizer_class = transformers.BertTokenizer\n",
        "pretrained_weights='bert-base-uncased'\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "bert_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwAb_T4HQHtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq = 100\n",
        "def tokenize_text(df, max_seq):\n",
        "    return [\n",
        "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.comment_text.values\n",
        "    ]\n",
        "def pad_text(tokenized_text, max_seq):\n",
        "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
        "\n",
        "def tokenize_and_pad_text(df, max_seq):\n",
        "    tokenized_text = tokenize_text(df, max_seq)\n",
        "    padded_text = pad_text(tokenized_text, max_seq)\n",
        "    return torch.tensor(padded_text)\n",
        "def targets_to_tensor(df, target_columns):\n",
        "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4GjtDVOQHtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71e60f3c-7edf-444e-dcba-6888e8051b8c"
      },
      "source": [
        "\n",
        "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
        "print('train indices done')\n",
        "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
        "print('val indices done')\n",
        "test_indices = tokenize_and_pad_text(df_test, max_seq)\n",
        "print('test indices done')\n",
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_indices.long())[0] \n",
        "    print('x_train conversion done')\n",
        "    x_val = bert_model(val_indices)[0]\n",
        "    print('x_val conversion done')\n",
        "    x_test = bert_model(test_indices)[0]\n",
        "    print('x_test conversion done')\n",
        "y_train = targets_to_tensor(df_train, target_columns)\n",
        "print('y_train conversion done')\n",
        "y_val = targets_to_tensor(df_val, target_columns)\n",
        "print('y_val conversion done')\n",
        "y_test = targets_to_tensor(df_test, target_columns)\n",
        "print('y test conversion done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1457 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1863 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train indices done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1927 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2829 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val indices done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test indices done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkDWn4IyQHtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3zSEkHKQHtQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3aacd4f7-2bbc-4ee8-ccc1-b2c343bc9243"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1194,  0.3158,  0.3344,  ..., -0.1921,  0.3971,  0.6479],\n",
              "        [ 0.6698,  1.4430,  1.5074,  ...,  0.1853, -0.2839,  0.1634],\n",
              "        [ 0.1701,  0.2929,  1.1660,  ...,  0.2320,  0.2287, -0.0210],\n",
              "        ...,\n",
              "        [ 0.0364,  0.2902,  0.3817,  ...,  0.2505,  0.1366,  0.7364],\n",
              "        [-0.3466,  0.2196,  0.9799,  ...,  0.0748,  0.4360,  0.9141],\n",
              "        [-0.2501,  0.2109,  0.5041,  ..., -0.2708,  0.7565,  0.6852]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcSwRE7tQHtV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ca7b196-4daf-4f67-d1f3-a393f3f52ded"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkKQL4wIQHtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KimCNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
        "        super(KimCNN, self).__init__()\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        \n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.sigmoid(logit)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Vl6esAQHtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_num = x_train.shape[1]\n",
        "embed_dim = x_train.shape[2]\n",
        "class_num = y_train.shape[1]\n",
        "kernel_num = 3\n",
        "kernel_sizes = [2, 3, 4]\n",
        "dropout = 0.5\n",
        "static = True\n",
        "model = KimCNN(\n",
        "    embed_num=embed_num,\n",
        "    embed_dim=embed_dim,\n",
        "    class_num=class_num,\n",
        "    kernel_num=kernel_num,\n",
        "    kernel_sizes=kernel_sizes,\n",
        "    dropout=dropout,\n",
        "    static=static,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_joFbAQHtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 10\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D3uol2nQHtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsQD4kI-v-1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b69531ed-6286-4612-b638-7bb46a81e355"
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "    with torch.no_grad(): \n",
        "            val_loss, batch = 0, 1\n",
        "            for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "                y_pred = model(x_batch)\n",
        "                loss = loss_fn(y_pred, y_batch)\n",
        "                val_loss += loss.item()\n",
        "            val_loss /= batch\n",
        "            val_losses.append(val_loss)\n",
        "            print(\"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"% (epoch + 1, train_losses[-1], val_losses[-1], elapsed))\n",
        "            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.63s.\n",
            "Epoch 2 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.70s.\n",
            "Epoch 3 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.75s.\n",
            "Epoch 4 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.47s.\n",
            "Epoch 5 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.57s.\n",
            "Epoch 6 Train loss: 0.08. Validation loss: 0.09. Elapsed time: 15.60s.\n",
            "Epoch 7 Train loss: 0.09. Validation loss: 0.09. Elapsed time: 15.69s.\n",
            "Epoch 8 Train loss: 0.08. Validation loss: 0.09. Elapsed time: 15.82s.\n",
            "Epoch 9 Train loss: 0.08. Validation loss: 0.09. Elapsed time: 15.83s.\n",
            "Epoch 10 Train loss: 0.08. Validation loss: 0.09. Elapsed time: 15.72s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH171kENwBRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4e345515-7d17-4e55-d64b-221934377007"
      },
      "source": [
        "plt.plot(train_losses, label=\"Training loss\")\n",
        "plt.plot(val_losses, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Losses\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QAxqFIFzJ-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval() # disable dropout for deterministic output\n",
        "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "    y_preds = []\n",
        "    batch = 0\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
        "    y_preds_np = np.array(y_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCSAXxJnzSS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b4609288-ffda-4471-bbd4-b3c5735fb975"
      },
      "source": [
        "y_preds_np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.17942201e-04, 2.35123791e-12, 1.57843726e-06, 6.41837996e-14,\n",
              "        2.62668368e-06, 9.20249335e-08],\n",
              "       [5.42864995e-03, 6.15100646e-08, 1.80015297e-04, 8.75959361e-10,\n",
              "        3.12687363e-04, 7.26215603e-06],\n",
              "       [4.45767277e-04, 1.96976411e-11, 5.17533999e-06, 7.45361021e-13,\n",
              "        7.51772313e-06, 2.35709848e-07],\n",
              "       ...,\n",
              "       [1.51395367e-03, 5.13346532e-10, 3.58205580e-05, 4.99009237e-11,\n",
              "        4.41874654e-05, 1.78684058e-06],\n",
              "       [4.03595404e-05, 1.18596361e-14, 1.41359109e-07, 3.54629349e-16,\n",
              "        2.37233436e-07, 3.89933730e-09],\n",
              "       [2.55502877e-04, 1.16085050e-11, 1.73522142e-06, 4.11508697e-14,\n",
              "        3.67015105e-06, 4.57644873e-08]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2UqkuOKzTmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a61a6dd5-7253-4c4b-a949-b7c7dfae1bf3"
      },
      "source": [
        "y_test_np = df_test[target_columns].values\n",
        "y_test_np[1000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlF5LnWLzV2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6ec172f0-3853-47c1-974f-bc2742b5fb30"
      },
      "source": [
        "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
        "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
        "df_accuracy.sort_values('auc')[::-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>severe_toxic</td>\n",
              "      <td>0.942452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>insult</td>\n",
              "      <td>0.914993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>toxic</td>\n",
              "      <td>0.913650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>obscene</td>\n",
              "      <td>0.898657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>identity_hate</td>\n",
              "      <td>0.897214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>threat</td>\n",
              "      <td>0.853333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           label       auc\n",
              "1   severe_toxic  0.942452\n",
              "4         insult  0.914993\n",
              "0          toxic  0.913650\n",
              "2        obscene  0.898657\n",
              "5  identity_hate  0.897214\n",
              "3         threat  0.853333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKz7uIepzcJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test_targets = df_test[target_columns]\n",
        "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
        "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oEPo-mrzgPv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5ec9dffd-7f9a-47f0-e2df-efe2d8b1b4e3"
      },
      "source": [
        "df_test_targets.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "toxic            186\n",
              "severe_toxic      17\n",
              "obscene           98\n",
              "threat             5\n",
              "insult            96\n",
              "identity_hate     18\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwNSZGB-zjK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8d0acee6-958b-44ed-a0fd-ac598bcde1f4"
      },
      "source": [
        "df_pred_targets.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHvmwSrPzl1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}